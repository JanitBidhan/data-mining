{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dbe4301",
   "metadata": {},
   "source": [
    "#HW2 (584) Credit Risk Prediction\n",
    "\"\"\" \n",
    "The objective of this assignment are the following: \n",
    "\n",
    "Experiment with various classification models.\n",
    "Think about dealing with data with different attribute types: categorical and numerical (ratio).\n",
    "Think about dealing with potentially sensitive or protected attributes like gender, race, age\n",
    "Think about dealing with imbalanced data i.e., class labels with varying distribution\n",
    "F1 Scoring Metric\n",
    "\n",
    "AIM: Develop predictive models that can determine someoneâ€™s credit risk 0 - high risk, 1-low risk .\n",
    "--\n",
    "\n",
    "The goal of this competition is to allow you to develop predictive models that can determine given a particular individual whether their credit risk is high denoted by 0 or low denoted by1.  As such, the goal would be to develop the best binary classification model.\n",
    "\n",
    "Since the dataset is imbalanced the scoring function will be the F1-score instead of Accuracy.\n",
    "\n",
    "Caveats:\n",
    "\n",
    "+ Remember not all features will be good for predicting credit risk. Think of feature selection, engineering, reduction\n",
    "\n",
    "+ The dataset has an imbalanced distribution i.e., within the training set there are 24720 (0) and 7841 (1). No information is provided for the test set regarding the distribution.\n",
    "\n",
    "+ Use your data mining knowledge till now, wisely to optimize your results.\n",
    "--------------------------------\n",
    "\n",
    "Data Description:\n",
    "\n",
    "The training dataset consists of 32561 records and the test dataset consists of 13305 records. We provide you with the training class labels and the test labels are held out.\n",
    "\n",
    "In the training file there are 13th attributes with the 13-th attribute (or column) being the class label of interest. In the testing file there are 12 attributes.\n",
    "\n",
    "train.csv\n",
    "Description\n",
    "\"\"\"\n",
    "id - unique identifier - UID\n",
    "F1 - Continuous value describing number of years since last degree was completed- YEARS_TO_LAST_DEGREE\n",
    "F2 - Continuous value indicating hours worked per week -WORK_HOURS_PER_WEEK\n",
    "F3 - Categorical Value - CAT_VALUE\n",
    "F4 - Categorical Value indicating type of occupation -CAT_VALUE_OCCUPATION\n",
    "F5 - continuous value denoting gains -GAINS\n",
    "F6 - continuous value denoting loss - LOSS\n",
    "F7 - Categorical value denoting marital status -MARITAL_STATUS\n",
    "F8 - Categorical value denoting type of employment (e.g., Self) -TYPE_EMPLOYMENT\n",
    "F9 - Categorical Value denoting education type -TYPE_EDUCATION\n",
    "F10 - Categorical Value denoting different race -TYPE_RACE\n",
    "F11 - Categorical - Female/Male -TYPE_GENDER\n",
    "credit - 0: Bad, 1: Good -CREDIT_RISK\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16164ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the Libraries\n",
    "import re\n",
    "import timeit\n",
    "import unicodedata\n",
    "import matplotlib.pylab as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.over_sampling import  SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2973e0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file and store the data\n",
    "def readTrainfile(filepath):\n",
    "    read_data = pd.read_csv(filepath, names=['UID', 'YEARS_TO_LAST_DEGREE','WORK_HOURS_PER_WEEK','CAT_VALUE', 'CAT_VALUE_OCCUPATION','GAINS','LOSS','MARITAL_STATUS','TYPE_EMPLOYMENT','TYPE_EDUCATION','TYPE_RACE','TYPE_GENDER','CREDIT_RISK'], sep=',',header=1)\n",
    "    return read_data\n",
    "\n",
    "\n",
    "# Read the file and store the data\n",
    "def readtestfile(filepath):\n",
    "    read_data = pd.read_csv(filepath, names=['UID', 'YEARS_TO_LAST_DEGREE','WORK_HOURS_PER_WEEK','CAT_VALUE', 'CAT_VALUE_OCCUPATION','GAINS','LOSS','MARITAL_STATUS','TYPE_EMPLOYMENT','TYPE_EDUCATION','TYPE_RACE','TYPE_GENDER'], sep=',',header=0)\n",
    "    return read_data\n",
    "\n",
    "\n",
    "# Save the file the output file\n",
    "def saveOutput(filePath, data):\n",
    "    # writing to .txt\n",
    "    np.savetxt(filePath, data, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77cc38d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData=readTrainfile(\"credit_train.csv\")\n",
    "testingData=readtestfile(\"credit_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c09b9dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the null columns where all values are null\n",
    "trainingData = trainingData.dropna(axis='columns', how='all')\n",
    "#testingData = testingData.dropna(axis='columns', how='all')\n",
    "\n",
    "# Drop the null rows\n",
    "trainingData = trainingData.dropna()\n",
    "#testingData = testingData.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef773765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of          UID  YEARS_TO_LAST_DEGREE  WORK_HOURS_PER_WEEK  CAT_VALUE  \\\n",
       "0          0                     7                   40          3   \n",
       "1          1                    12                   40          0   \n",
       "2          2                    10                   40          0   \n",
       "3          3                    10                   30          3   \n",
       "4          4                     6                   30          1   \n",
       "...      ...                   ...                  ...        ...   \n",
       "13300  13300                    13                   40          3   \n",
       "13301  13301                    13                   36          1   \n",
       "13302  13302                     9                   40          2   \n",
       "13303  13303                    13                   50          0   \n",
       "13304  13304                    13                   40          3   \n",
       "\n",
       "       CAT_VALUE_OCCUPATION  GAINS  LOSS  MARITAL_STATUS  TYPE_EMPLOYMENT  \\\n",
       "0                         7      0     0               4                4   \n",
       "1                        11      0     0               2                2   \n",
       "2                         7   7688     0               2                4   \n",
       "3                         0      0     0               4                0   \n",
       "4                         8      0     0               4                4   \n",
       "...                     ...    ...   ...             ...              ...   \n",
       "13300                    10      0     0               4                4   \n",
       "13301                    10      0     0               0                4   \n",
       "13302                     0      0     0               6                0   \n",
       "13303                    10      0     0               2                4   \n",
       "13304                     1   5455     0               0                4   \n",
       "\n",
       "       TYPE_EDUCATION            TYPE_RACE TYPE_GENDER  \n",
       "0                   1                Black        Male  \n",
       "1                   7                White        Male  \n",
       "2                  15                Black        Male  \n",
       "3                  15                White      Female  \n",
       "4                   0                White        Male  \n",
       "...               ...                  ...         ...  \n",
       "13300               9                White        Male  \n",
       "13301               9                White      Female  \n",
       "13302              11                Black        Male  \n",
       "13303               9                White        Male  \n",
       "13304               9   Asian-Pac-Islander        Male  \n",
       "\n",
       "[13305 rows x 12 columns]>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testingData.describe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1cfef1",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Categorical- \n",
    "PROCESSING AS ONE HOT ENCODING\n",
    "F3 - Categorical Value - CAT_VALUE\n",
    "F4 - Categorical Value indicating type of occupation -CAT_VALUE_OCCUPATION\n",
    "F7 - Categorical value denoting marital status -MARITAL_STATUS\n",
    "F8 - Categorical value denoting type of employment (e.g., Self) -TYPE_EMPLOYMENT\n",
    "F9 - Categorical Value denoting education type -TYPE_EDUCATION\n",
    "F10 - Categorical Value denoting different race -TYPE_RACE \n",
    "-- \n",
    "PROCESSING AS BOOLEAN\n",
    "F11 - Categorical - Female/Male -TYPE_GENDER \n",
    "Continuous\n",
    "F1 - Continuous value describing number of years since last degree was completed- YEARS_TO_LAST_DEGREE\n",
    "F2 - Continuous value indicating hours worked per week -WORK_HOURS_PER_WEEK\n",
    "F5 - continuous value denoting gains -GAINS\n",
    "F6 - continuous value denoting loss - LOSS\n",
    "\n",
    "CLASS\n",
    "credit - 0: Bad, 1: Good -CREDIT_RISK\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2be6d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do one hot encoding for the column_Name \n",
    "def ONE_HOT_ENCODING(dataset, column_Name, prefix, remove_Original):\n",
    "    new_columns=pd.get_dummies(dataset[column_Name],prefix=prefix)\n",
    "    if(remove_Original):\n",
    "        dataset=dataset.drop(columns=[column_Name])\n",
    "    dataset=pd.concat([dataset, new_columns], axis=1)\n",
    "    #print(dataset)\n",
    "    return dataset\n",
    "\n",
    "# Split a dataset into k folds\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "    # Drop the null rows\n",
    "    dataset = dataset.dropna()\n",
    "    dataset = dataset.reset_index(drop=True)\n",
    "    X, y = dataset.drop(['CREDIT_RISK'],axis=1), dataset['CREDIT_RISK']\n",
    "    skf = StratifiedKFold(n_splits=n_folds)\n",
    "    #print(X,y)\n",
    "    dataset_folds = list()\n",
    "    for training_set_idx, test_set_idx in skf.split(X, y):\n",
    "        fold = {\"training_set_X\": X.iloc[training_set_idx], \"test_set_X\": X.iloc[test_set_idx],\n",
    "                \"training_set_Y\": y.iloc[training_set_idx], \"test_set_Y\": y.iloc[test_set_idx],\n",
    "                \"test_idx\": test_set_idx}\n",
    "        dataset_folds.append(fold)\n",
    "    return dataset_folds\n",
    "\n",
    "#Do one hot encoding, binary conversion of data and normaliztion\n",
    "def clean_data(processed_data):\n",
    "    #CONVERTING CATEGORICAL_COULMNS VIA ONE_HOT_ENCODING\n",
    "    CATEGORICAL_COULMNS=[\"CAT_VALUE\",\"CAT_VALUE_OCCUPATION\",\"MARITAL_STATUS\",\"TYPE_EMPLOYMENT\", \"TYPE_EDUCATION\",\"TYPE_RACE\"]    #    CATEGORICAL_COULMNS=[\"CAT_VALUE\",\"CAT_VALUE_OCCUPATION\",\"MARITAL_STATUS\",\"TYPE_EMPLOYMENT\", \"TYPE_EDUCATION\",\"TYPE_RACE\"]\n",
    "    for col in CATEGORICAL_COULMNS:\n",
    "        processed_data=ONE_HOT_ENCODING(processed_data,col,col,True)\n",
    "    #CONVERTING GENDER TO BINARY\n",
    "    IS_FEMALE = {' Male': 0,' Female': 1}\n",
    "    processed_data.TYPE_GENDER = [IS_FEMALE[item] for item in processed_data.TYPE_GENDER]\n",
    "    processed_data=processed_data.rename(columns={'TYPE_GENDER':'IS_FEMALE'})\n",
    "    #DROPPING UID CCOLUMN \n",
    "    processed_data=processed_data.drop(columns=['UID'])\n",
    "    #NORMALIZING ALL THE CONTINUOUS COLUMNS\n",
    "    cols_to_norm = ['YEARS_TO_LAST_DEGREE','WORK_HOURS_PER_WEEK','GAINS','LOSS']\n",
    "    processed_data[cols_to_norm] = RobustScaler().fit_transform(processed_data[cols_to_norm])\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4f5b4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_processing_data=trainingData.copy()\n",
    "training_processing_data=trainingData.copy()\n",
    "# Drop the null columns where all values are null\n",
    "training_processing_data = training_processing_data.dropna(axis='columns', how='all')\n",
    "training_processing_data=clean_data(training_processing_data)\n",
    "test_processing_data=testingData.copy()\n",
    "test_processing_data=clean_data(test_processing_data)\n",
    "index_catagorical_columns= list(range(6, 63))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd71e6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 0 1 0]\n",
      "GradientBoostingClassifier:\n"
     ]
    }
   ],
   "source": [
    "def getTestingData(trainingData, testData):\n",
    "    TrainX, Trainy = trainingData.drop(['CREDIT_RISK'],axis=1), trainingData['CREDIT_RISK']\n",
    "    fold = {\"training_set_X\": TrainX, \"test_set_X\": testData,\n",
    "                \"training_set_Y\": Trainy}\n",
    "    return fold\n",
    "def Classification_Algo_Test(algo, Dataset,name ):\n",
    "    X_test=Dataset[\"test_set_X\"]\n",
    "    X_train=Dataset[\"training_set_X\"]\n",
    "    y_train=Dataset[\"training_set_Y\"]\n",
    "    predictedOutput=dict()\n",
    "    sm = SMOTENC(random_state=42, categorical_features=index_catagorical_columns)\n",
    "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "    algo.fit(X_train, y_train)\n",
    "    y_predicted = algo.predict(X_test)\n",
    "    print(y_predicted)\n",
    "    print(\"%s:\" % name)\n",
    "    predictedOutput[name]= y_predicted\n",
    "    return predictedOutput\n",
    "\n",
    "#LRegressionD=Classification_Algo_Test(LogisticRegression(),getTestingData(training_processing_data,test_processing_data),\"LogisticRegression\")\n",
    "#saveOutput(\"LRegressionDSMOTEENN.txt\", LRegressionD['LogisticRegression'])\n",
    "\n",
    "#GaussianNBD=Classification_Algo_Test(GaussianNB(),getTestingData(training_processing_data,test_processing_data),\"GaussianNB\")\n",
    "#saveOutput(\"GaussianNBSMOTEENN.txt\", GaussianNBD['GaussianNB'])\n",
    "\n",
    "#LinearSVCD=Classification_Algo_Test(LinearSVC(random_state=0),getTestingData(training_processing_data,test_processing_data),\"LinearSVC\")\n",
    "#saveOutput(\"LinearSVCSMOTEENN.txt\", LinearSVCD['LinearSVC'])\n",
    "\n",
    "#RandomForestClassifierD=Classification_Algo_Test(RandomForestClassifier(),getTestingData(training_processing_data,test_processing_data),\"RandomForestClassifier\")\n",
    "#saveOutput(\"RandomForestClassifierSMOTEENN.txt\", RandomForestClassifierD['RandomForestClassifier'])\n",
    "\n",
    "GradientBoostingClassifierD=Classification_Algo_Test(GradientBoostingClassifier(n_estimators=50,max_depth=10,max_features=None),getTestingData(training_processing_data,test_processing_data),\"GradientBoostingClassifier\")\n",
    "saveOutput(\"GradientBoostingClassifier10MaxNone4.txt\", GradientBoostingClassifierD['GradientBoostingClassifier'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03e9e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da2aff2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
